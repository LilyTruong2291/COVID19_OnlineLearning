{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install required packages for data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install -U textblob\n",
        "!python -m textblob.download_corpora\n",
        "!pip install fuzzywuzzy\n",
        "!pip install python-Levenshtein\n",
        "!pip install emoji --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import fuzzywuzzy\n",
        "from fuzzywuzzy import process\n",
        "import chardet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load datasets"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "location1 = pd.read_excel(r\"location.xlsx\")\n",
        "location2 = pd.read_excel(r\"location1.xlsx\")\n",
        "df = pd.read_excel(r\"tweets.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "location = pd.concat([location1,location2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "tags": []
      },
      "cell_type": "code",
      "source": [
        "location.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "merge = pd.merge(df, location, how = 'left', on = 'screen_name')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "tags": []
      },
      "cell_type": "code",
      "source": [
        "merge.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# % of missing.\n",
        "for col in merge.columns:\n",
        "    pct_missing = np.mean(merge[col].isnull())\n",
        "    print('{} - {}%'.format(col, round(pct_missing*100)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# remove duplicates\n",
        "merge.drop_duplicates(subset=[\"text\",\"timestamp\"], keep='first', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "merge.dropna(subset=['location'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merge = merge.drop(merge[merge.retweets > 0].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merge=merge.drop(['Unnamed: 0_x','Unnamed: 0_y','has_media', 'img_urls', 'is_replied',\n",
        "       'is_reply_to', 'likes', 'links', 'parent_tweet_id', 'replies',\n",
        "       'reply_to_users','text_html','tweet_id', 'tweet_url', 'user_id','video_url'], axis=1)"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "tags": []
      },
      "cell_type": "code",
      "source": [
        "merge.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re \n",
        "from textblob import TextBlob \n",
        "import emoji  \n",
        "\n",
        "def clean_tweet(text): \n",
        "    text = re.sub(r'@[A-Za-z0-9]+', '', str(text)) # remove @mentions\n",
        "    text = re.sub(r'#', '',  str(text)) # remove the '#' symbol\n",
        "    text = re.sub(r'RT[\\s]+', '',  str(text)) # remove RT\n",
        "    text = re.sub(r'https?\\/\\/S+', '',  str(text)) # remove the hyperlink\n",
        "    text = re.sub(r'http\\S+', '',  str(text)) # remove the hyperlink\n",
        "    text = re.sub(r'www\\S+', '',  str(text)) # remove the www\n",
        "    text = re.sub(r'twitter+', '',  str(text)) # remove the twiiter\n",
        "    text = re.sub(r'pic+', '',  str(text)) # remove the pic\n",
        "    text = re.sub(r'com', '',  str(text)) # remove the pic\n",
        "\n",
        "    return text\n",
        "\n",
        "def remove_emoji(text):\n",
        "    return emoji.get_emoji_regexp().sub(u'', text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merge['text'] = merge['text'].apply(clean_tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merge['text'] = merge['text'].apply(remove_emoji)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merge['text'] = [text.lower() for text in merge['text']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "def getSubjectivity(text):\n",
        "    return TextBlob( str(text)).sentiment.subjectivity\n",
        "\n",
        "def getPolarity(text):\n",
        "    return TextBlob( str(text)).sentiment.polarity\n",
        "\n",
        "# merge['Subjectivity'] = merge['text'].apply(getSubjectivity)\n",
        "# merge['Polarity'] = merge['text'].apply(getPolarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "merge['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# load library\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# download the set of stop words the first time\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load stop words\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# Show stop words\n",
        "stop_words[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove stop words\n",
        "merge['clean_tweets'] = merge['text'].apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stop_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "merge['clean_tweets']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# convert to lower case\n",
        "merge['location'] = merge['location'].str.lower()\n",
        "# remove trailing white spaces\n",
        "merge['location'] = merge['location'].str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_location(text): \n",
        "    # text = re.sub(r'[@?|$|.|!|0-9|Â°|\\|/|#|()]', '', str(text)) # remove not a letters \n",
        "    text = re.sub(r'[^a-zA-Z]+', ' ', str(text)) # remove not a letters \n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merge['clean_location'] = merge['location'].apply(clean_location)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merge['clean_location'] = merge['clean_location'].apply(remove_emoji)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merge.to_excel(\"all.xlsx\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python_defaultSpec_1596739312152",
      "display_name": "Python 3.7.4 64-bit ('base': conda)",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
